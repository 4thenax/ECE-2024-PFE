{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\const\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\const\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import pygame\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from midiutil import MIDIFile\n",
    "from pydub import AudioSegment\n",
    "import base64\n",
    "\n",
    "import streamlit as st\n",
    "from music21 import stream, note, converter, metadata\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégories et descriptions\n",
    "categories = {\n",
    "    \"Aircraft\": \"plane, airplane, airport\",\n",
    "    \"Animals\": \"farm, donkey, pig, cow, duck, goose, pigeon, horse, ox, ram, buffalo, sheep, ice_bear\",\n",
    "    \"Applause\":\"applause, show, performance, scene, cabaret\",\n",
    "    \"Atmosphere\":\"atmosphere\",\n",
    "    \"Bells\":\"bell, church, altar\",\n",
    "    \"Birds\":\"bird, goose\",\n",
    "    \"Clocks\":\"clock, ticker, time\",\n",
    "    \"Crowds\":\"crowd, people\",\n",
    "    \"Daily Life\" : \"chill, coffee_shop, coffee, library, book, restaurant, tray\",\n",
    "    \"Destruction\": \"destruction\",\n",
    "    \"Electronics\":\"machine, computer, electronic\",\n",
    "    \"Events\":\"firework, festival, party, concert\",\n",
    "    \"Fire\":\"fire, wood, campfire, tents, camping\",\n",
    "    \"Footsteps\":\"footsetps, run, walk\",\n",
    "    \"Machines\":\"machine\",\n",
    "    \"Medical\":\"hospital, sick, invalid, ill, unhealthy\",\n",
    "    \"Military\":\"soldier, war, military, weapon, gun, battle, fog, volcano\",\n",
    "    \"Nature\": \"tree, bench, park_bench, sun, water, sea, sunset, seaside, valley, forest, fountain, lakeside, sand, cliff, ice floe, palm, cascade, flower\",\n",
    "    \"Sports\":\"tennis, basketball, ball, football, swimming-pool, swimming, horse, horse racing, boat\",\n",
    "    \"Toys\":\"toy, children toy, puzzle\",\n",
    "    \"Transport\":\"train, station train, cars, bus, taxi\", \n",
    "}\n",
    "\n",
    "# Catégories d'instrument MIDI (donne intervalle d'instrus possibles)\n",
    "categories_instruments = {\n",
    "    \"Aircraft\": (96, 103),  # SFX Sci-fi à SFX Atmosphere\n",
    "    \"Animals\": (113, 123),  # Tinkle Bell à Bird Tweet\n",
    "    \"Applause\": (126, 127),  # Applause\n",
    "    \"Atmosphere\": (88, 94),  # New Age Syn Pad à Halo Syn Pad\n",
    "    \"Bells\": (13, 14),  # Xylophone, Tubular Bells\n",
    "    \"Birds\": (72, 78),  # Piccolo à Ocarina\n",
    "    \"Clocks\": (0, 7),  # Acoustic Grand Piano à Clavinet\n",
    "    \"Crowds\": (48, 62),  # String Ensemble 1 à Syn Brass 2\n",
    "    \"Daily Life\": (24, 31),  # Guitar\n",
    "    \"Destruction\": (116, 118),  # Melodic Tom à Syn Drum\n",
    "    \"Electronics\": (80, 127),  # Syn Square Wave à Gun Shot\n",
    "    \"Events\": (48, 62),  # String Ensemble 1 à Syn Brass 2\n",
    "    \"Fire\": (97, 99),  # SFX Soundtrack à SFX Brightness\n",
    "    \"Footsteps\": (115, 115),  # Woodblock\n",
    "    \"Machines\": (0, 118),  # Acoustic Grand Piano à Syn Drum\n",
    "    \"Medical\": (88, 94),  # New Age Syn Pad à Halo Syn Pad\n",
    "    \"Military\": (56, 61),  # Trumpet à Brass Section\n",
    "    \"Nature\": (72, 76),  # Piccolo à Bottle Blow\n",
    "    \"Sports\": (56, 62),  # Trumpet à Syn Brass 2\n",
    "    \"Toys\": (112, 118),  # Tinkle Bell à Syn Drum\n",
    "    \"Transport\": (97, 127)  # SFX Soundtrack à Gun Shot\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './pierre_boulez.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017FC944E0C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "Label 1: tray\n",
      "Label 2: envelope\n",
      "Label 3: handkerchief\n"
     ]
    }
   ],
   "source": [
    "# Charger un modèle pré-entraîné (par exemple, VGG16)\n",
    "# https://github.com/tkeldenich/VGG16_SimplyUse\n",
    "\n",
    "model = VGG16()\n",
    "\n",
    "# Charger l'image\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))  # Redimensionner à la taille attendue par le modèle\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prétraitement pour le modèle\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# Prédiction\n",
    "prediction = model.predict(image)\n",
    "labels = decode_predictions(prediction)\n",
    "# Extraire les labels individuels\n",
    "label1, label2, label3 = None, None, None\n",
    "\n",
    "if len(labels[0]) > 0:\n",
    "    label1 = labels[0][0][1]  # Premier label\n",
    "    \n",
    "\n",
    "if len(labels[0]) > 1:\n",
    "    label2 = labels[0][1][1]  # Deuxième label\n",
    "    \n",
    "\n",
    "if len(labels[0]) > 2:\n",
    "    label3 = labels[0][2][1]  # Troisième label\n",
    "\n",
    "# Afficher les labels\n",
    "print(\"Label 1:\", label1)\n",
    "print(\"Label 2:\", label2)\n",
    "print(\"Label 3:\", label3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catégorie correspondante : Daily Life\n",
      "tray\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer la similarité entre les labels et les catégories\n",
    "def trouver_categorie(labels, categories):\n",
    "    vect = TfidfVectorizer()\n",
    "    descriptions = list(categories.values())\n",
    "    vect.fit(descriptions)\n",
    "    cat_vectors = vect.transform(descriptions)\n",
    "\n",
    "    label_vector = vect.transform([\" \".join(labels)])\n",
    "    sim_scores = cosine_similarity(label_vector, cat_vectors)\n",
    "\n",
    "    # Trouver la catégorie avec le score de similarité le plus élevé\n",
    "    categorie_index = np.argmax(sim_scores)\n",
    "    categorie = list(categories.keys())[categorie_index]\n",
    "    return categorie\n",
    "\n",
    "# Labels extraits de l'image\n",
    "labels_extraits = [label1, label2, label3]  # Remplacer par les labels réels\n",
    "\n",
    "# Trouver la catégorie correspondante\n",
    "categorie_correspondante = trouver_categorie(labels_extraits, categories)\n",
    "print(\"Catégorie correspondante :\", categorie_correspondante)\n",
    "print (label1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau associant tonalité à caractère\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
